{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wXhKzBOn-rt"
   },
   "source": [
    "**LMs and Knowledge Bases** \n",
    "\n",
    "This notebook is designed to be run in Google Colab:\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg#left)](https://colab.research.google.com/github/MMesgar/summer_school_2022/blob/main/LM_POD.ipynb)\n",
    "\n",
    "If you want to save your progress online, a Google account is required.\n",
    "Before you start, you should change the Google Colab runtime type under Runtime->Change runtime type->Hardware accelerator to GPU.\n",
    "\n",
    "In the exercise, we are asked to focus on three relation types. These relation types are \"place of birth (POB)\", \"date of birth (DOP)\", and \"place of death (POD)\". This solution is designed for the POD. However, you should be able to learn how to design a similar solution for POB and DOP as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yG6tyFR-pY0V"
   },
   "source": [
    "First we install the transformers architecture because we are going to use BERT (https://en.wikipedia.org/wiki/BERT_(language_model)), a machine learning model for natural language processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BV90Zaf2i8Gf",
    "outputId": "0110f149-1518-4b41-b1e4-dc4fa50bcc53"
   },
   "outputs": [],
   "source": [
    "%pip install datasets transformers[sentencepiece] --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEAdv0g-qJzm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We read the content of the file using the Pandas package (https://pandas.pydata.org) in Python. To use Pandas we first import it.\n",
    "Then we read the contents of the place of death test file from GitHub. (Ignore the other two for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#pod = pd.read_json('https://raw.githubusercontent.com/MMesgar/summer_school_2022/main/sample_data/place_of_death_test.jsonl', lines=True)\n",
    "#pob = pd.read_json('https://raw.githubusercontent.com/MMesgar/summer_school_2022/main/sample_data/place_of_birth_test.jsonl', lines=True)\n",
    "#dob = pd.read_json('https://raw.githubusercontent.com/MMesgar/summer_school_2022/main/sample_data/date_of_birth_test.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8HRHmt9w_ED"
   },
   "source": [
    "Let's see how many facts do exist in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBga13yVw-SG",
    "outputId": "5c5fb0b2-d456-485e-eea4-018945423798"
   },
   "outputs": [],
   "source": [
    "num_facts = len(pod)\n",
    "print(f\"Number of POD (place of death) facts is: {num_facts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCtl3UBZqQVw"
   },
   "source": [
    "Let's take a look at 5 top rows in the pod dataframe. The ``head()`` function does this action for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "VUpvllohguPz",
    "outputId": "47731b3d-9b6a-4f1c-db92-93ca79f1d764"
   },
   "outputs": [],
   "source": [
    "pod.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cv5-lOodqhc5"
   },
   "source": [
    "Look at the column names, two of them are important for us: 'sub_label' and 'obj_label'. These columns show which person died in which city and we will reduce the dataset to these two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "apYh7Es7g1J6"
   },
   "outputs": [],
   "source": [
    "pod_data_samples = pod[['sub_label','obj_label']]\n",
    "pod_data_samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmZMs8U8q5qR"
   },
   "source": [
    "Now we create a list of subjects, persons, and their corresponding objects, the city where they died."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6rxpbnD0hlXg"
   },
   "outputs": [],
   "source": [
    "subjects = pod['sub_label'].to_list()\n",
    "reference_objects = pod['obj_label'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-jPmDwHrJ9Z"
   },
   "source": [
    "Now we are ready to use BERT. The idea is to give each subject to BERT and see what it returns as the city where the person died. \n",
    "\n",
    "Let's tell the pipeline to use BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HKropHgblWoR",
    "outputId": "1c6d8936-4570-4583-9e6e-38f41b7f6215"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgagsPDxrilT"
   },
   "source": [
    "For any subject in the list, we define a template ``{s} died in [MASK]``. We give it to BERT and see what token it predicts as the object, instead of ``[MASK]``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BKM50FoZlgXK"
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for s in subjects:\n",
    "  predicted_obj = unmasker(f\"{s} died in [MASK].\")[0][\"token_str\"]\n",
    "  predictions.append(predicted_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geZ9sEU5r77L"
   },
   "source": [
    "Now we can evaluate how BERT performed. Let's look at 10 predicted labels and 10 reference objects. We can easily compare them manually. Right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zxLu0CpmWtg",
    "outputId": "37ae601e-0b83-4b82-9655-bb27ab24629c"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "  print(predictions[i], end=', ')\n",
    "  print(reference_objects[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVV3i8HssHwU"
   },
   "source": [
    "Although we can compare a short list of predicted and reference labels manually, we would be better off using code to compare the lists automatically if they contain many elements.\n",
    "The following function performs such a comparison and shows us which percentage of the labels were correctly predicted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XkKUSwC1lMO3",
    "outputId": "213bd601-7d07-4377-f021-6c17f25e3318"
   },
   "outputs": [],
   "source": [
    "correct_1 = 0.0\n",
    "for i in range(num_facts):\n",
    "  predicted_label = predictions[i].lower()\n",
    "  ref_label = reference_objects[i].lower()\n",
    "  if predicted_label == ref_label:\n",
    "    correct_1 += 1\n",
    "\n",
    "p_at_1 = correct_1 / len(predictions)\n",
    "p_at_1 = p_at_1 * 100\n",
    "print(f\"number of facts is: {num_facts}, p@1 = {p_at_1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Additional Exercises*\n",
    "1. Can you improve the accuracy of the predictions made by BERT?\n",
    "2. BERT does not just give us one prediction, but ranks several according to the probability with which it predicted them as the reference object. How about if we consider not only the first predicted object, but for example the first 5 (p@5). Adjust the code to get p@5 in addition to p@1. How do these two differ?\n",
    "3. Now you can try the other two given sample datasets, first POB (place of birth), and after that DOB (data of birth)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lm-as-kb.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b460384b52104c1e5b9cf54bee46a255d22b2bef338f75ac4ad5d48196028d3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}