{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wXhKzBOn-rt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**LMs and Knowledge Bases** \n",
    "\n",
    "This notebook is designed to be run in Google Colab:\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg#left)](https://colab.research.google.com/github/MMesgar/summer_school_2022/blob/main/LM_POD.ipynb)\n",
    "\n",
    "If you want to save your progress online, a Google account is required.\n",
    "Before you start, you should change the Google Colab runtime type under Runtime->Change runtime type->Hardware accelerator to GPU.\n",
    "\n",
    "In the exercise, we are asked to focus on three relation types. These relation types are \"place of birth (POB)\", \"date of birth (DOP)\", and \"place of death (POD)\". This solution is designed for the POD. However, you should be able to learn how to design a similar solution for POB and DOP as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yG6tyFR-pY0V",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First we install the transformers architecture because we are going to use BERT (https://en.wikipedia.org/wiki/BERT_(language_model)), a machine learning model for natural language processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BV90Zaf2i8Gf",
    "outputId": "0110f149-1518-4b41-b1e4-dc4fa50bcc53",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%pip install datasets transformers[sentencepiece] --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEAdv0g-qJzm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We read the content of the file using the Pandas package (https://pandas.pydata.org) in Python. To use Pandas we first import it.\n",
    "Then we read the contents of the place of death test file from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pod = pd.read_json('https://raw.githubusercontent.com/MMesgar/summer_school_2022/main/sample_data/place_of_death_test.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8HRHmt9w_ED",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's see how many facts do exist in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBga13yVw-SG",
    "outputId": "5c5fb0b2-d456-485e-eea4-018945423798",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_facts = len(pod)\n",
    "print(f\"Number of POD (place of death) facts is: {num_facts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCtl3UBZqQVw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's take a look at 5 top rows in the pod dataframe. The ``head()`` function does this action for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "VUpvllohguPz",
    "outputId": "47731b3d-9b6a-4f1c-db92-93ca79f1d764",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pod.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cv5-lOodqhc5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Look at the column names, two of them are important for us: 'sub_label' and 'obj_label'. These columns show which person died in which city and we will reduce the dataset to these two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "apYh7Es7g1J6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pod_data_samples = pod[['sub_label','obj_label']]\n",
    "pod_data_samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmZMs8U8q5qR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we create a list of subjects, persons, and their corresponding objects, the city where they died."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6rxpbnD0hlXg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subjects = pod['sub_label'].to_list()\n",
    "reference_objects = pod['obj_label'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-jPmDwHrJ9Z",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we are ready to use BERT. The idea is to give each subject to BERT and see what it returns as the city where the person died. \n",
    "\n",
    "Now we create what we call a pipeline which can perform a sequence of data processing and tell it to use BERT to fill a ``[MASK]``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HKropHgblWoR",
    "outputId": "1c6d8936-4570-4583-9e6e-38f41b7f6215",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgagsPDxrilT",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we use the first subject in a sentence and see what BERT predits for the placeholder ``[MASK]``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted_obj = unmasker(f\"{subjects[0]} died in [MASK].\")\n",
    "for obj in predicted_obj:\n",
    "  print(obj)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, BERT gives us 5 different possibilities, starting with the most likely one. You can also see that none of the predicted labels actually match the reference label.\n",
    "\n",
    "Now we define a template that goes through the list of all topics and makes a prediction for all of them. For now, we just use the most likely prediction and get the predicted token_str from that."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BKM50FoZlgXK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for s in subjects:\n",
    "  predicted_obj = unmasker(f\"{s} died in [MASK].\")[0][\"token_str\"]\n",
    "  predictions.append(predicted_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geZ9sEU5r77L",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can evaluate the performance of BERT. Let's look at the first 10 predicted designations and their corresponding reference objects. We can easily compare them manually, can't we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zxLu0CpmWtg",
    "outputId": "37ae601e-0b83-4b82-9655-bb27ab24629c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "table = [[\"Subject\", \"Prediction\", \"Reference\"]]\n",
    "\n",
    "for i in range(10):\n",
    "  table.append([subjects[i], predictions[i], reference_objects[i]])\n",
    "print(tabulate(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVV3i8HssHwU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Although we can compare a short list of predicted and reference labels manually, we would be better off using code to compare the lists automatically if they contain many elements.\n",
    "The following function performs such a comparison and shows us which percentage of the labels were correctly predicted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XkKUSwC1lMO3",
    "outputId": "213bd601-7d07-4377-f021-6c17f25e3318",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correct_1 = 0.0\n",
    "for i in range(num_facts):\n",
    "  predicted_label = predictions[i].lower()\n",
    "  ref_label = reference_objects[i].lower()\n",
    "  if predicted_label == ref_label:\n",
    "    correct_1 += 1\n",
    "\n",
    "p_at_1 = correct_1 / len(predictions)\n",
    "p_at_1 = p_at_1 * 100\n",
    "print(f\"number of facts is: {num_facts}, p@1 = {p_at_1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Additional Exercises*\n",
    "1. Can you improve the accuracy of the predictions made by BERT?\n",
    "2. BERT does not just give us one prediction, but ranks several according to the probability with which it predicted them as the reference object. How about if we consider not only the first predicted object, but for example the first 5 (p@5). Adjust the code to get p@5 in addition to p@1. How do these two differ?\n",
    "3. Now you can try the other two given sample datasets, first POB (place of birth), and after that DOB (data of birth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#pob = pd.read_json('https://raw.githubusercontent.com/MMesgar/summer_school_2022/main/sample_data/place_of_birth_test.jsonl', lines=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#dob = pd.read_json('https://raw.githubusercontent.com/MMesgar/summer_school_2022/main/sample_data/date_of_birth_test.jsonl', lines=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lm-as-kb.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b460384b52104c1e5b9cf54bee46a255d22b2bef338f75ac4ad5d48196028d3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}